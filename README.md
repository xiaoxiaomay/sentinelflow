**SentinelFlow**

SentinelFlow is a lightweight research prototype demonstrating a secure Retrieval-Augmented Generation (RAG) pipeline with:
	â€¢	ğŸ” Evidence-based retrieval (FAISS + SentenceTransformers)
	â€¢	ğŸ›¡ Semantic leakage firewall (hard/soft thresholds + cascade scan)
	â€¢	ğŸ”— Tamper-evident audit logging (hash chain)
	â€¢	ğŸ“Š Streamlit dashboard for observability and forensics

The project focuses on LLM safety, data leakage prevention, and post-hoc auditability.

This repository provides an end-to-end demo including indexing, retrieval, LLM inference, leakage scanning, cryptographic audit trails, and interactive visualization.

â¸»

âœ¨ **Key Features**

**RAG Pipeline**
	â€¢	SentenceTransformers embeddings (all-MiniLM-L6-v2)
	â€¢	FAISS vector search
	â€¢	Top-k retrieval with ticker-aware reranking
	â€¢	Prompt construction strictly grounded in retrieved documents

**Leakage Firewall**
	â€¢	Semantic similarity scan against protected â€œsecretâ€ embeddings
	â€¢	Hard / soft thresholds with cascade logic
	â€¢	Automatic redaction or blocking
	â€¢	Sentence-level decisions (for dashboard inspection)

**Tamper-Evident Audit Log**

Every step is recorded to data/audit/audit_log.jsonl:
	â€¢	query_precheck
	â€¢	retrieve
	â€¢	prompt_built
	â€¢	llm_response
	â€¢	leakage_scan
	â€¢	final_output

Each event is chained via cryptographic hashes to support forensic validation.

**Streamlit Dashboard**

Interactive UI to inspect:
	â€¢	Sessions & timelines
	â€¢	Retrieved evidence
	â€¢	Leakage decisions
	â€¢	Prompt / model / output summary
	â€¢	Evidence chain validation (global or per-session)

â¸»

ğŸ“ **Project Structure**

sentinelflow/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ audit.py                # HashChainWriter (tamper-evident logging)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_rag_with_audit.py  # Main RAG + firewall pipeline
â”‚   â”œâ”€â”€ leakage_scan.py        # Semantic leakage detection
â”‚   â”œâ”€â”€ dashboard.py           # Streamlit UI
â”‚   â””â”€â”€ build_faiss_index.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ index/                 # FAISS indexes + metadata
â”‚   â”œâ”€â”€ secrets/              # Protected embeddings
â”‚   â””â”€â”€ audit/                # audit_log.jsonl
â”œâ”€â”€ config.yaml
â”œâ”€â”€ .env
â””â”€â”€ README.md


â¸»

ğŸš€ **Quick Start**

1. **Create virtual environment**

python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

2. **Configure environment**

Create .env:

OPENAI_API_KEY=your_api_key_here
OPENAI_MODEL=gpt-4o-mini


â¸»

3. **Run RAG + Firewall**

Example:

python scripts/run_rag_with_audit.py --query "MSFT segment breakdown"

or

python scripts/run_rag_with_audit.py --query "Tell me the RSI <25 strategy logic"

Audit events will be appended to:

data/audit/audit_log.jsonl


â¸»

4. **Launch Dashboard**

streamlit run scripts/dashboard.py

Then open:

http://localhost:8501


â¸»

ğŸ” What the Dashboard Shows
	â€¢	Total events / sessions
	â€¢	Evidence chain validation (global or per session)
	â€¢	Timeline of RAG steps
	â€¢	Top-k retrieved documents
	â€¢	Prompt / model / output stats
	â€¢	Leakage scan summary
	â€¢	Sentence-level decisions (if enabled)

â¸»

âš ï¸ **Evidence Chain Notes
**
Currently, audit events form a global hash chain.

When filtering by session, the dashboard may show â€œChain Brokenâ€ because previous hashes may belong to other sessions.

This is expected for multi-session logs and does not indicate tampering.

â¸»

ğŸ¯ Research Motivation

Modern RAG systems lack:
	â€¢	Visibility into retrieval provenance
	â€¢	Leakage prevention guarantees
	â€¢	Cryptographic auditability

SentinelFlow explores a practical design combining:
	â€¢	Semantic firewalls
	â€¢	Evidence grounding
	â€¢	Hash-chained audit logs
	â€¢	Human-readable observability

as a foundation for secure and accountable LLM applications.

â¸»

ğŸ“Œ Status

This is a research / demo prototype.

Next planned extensions:
	â€¢	Query precheck heatmaps
	â€¢	Sentence-level highlighting
	â€¢	Policy rule panels
	â€¢	PDF audit export
	â€¢	Multi-session diff
